{
  "hash": "d1296f671c50909ded3b60a9d2567233",
  "result": {
    "engine": "jupyter",
    "markdown": "---\njupyter: python3\n---\n\n::: {#18a5c29e .cell editable='false' execution_count=1}\n``` {.python .cell-code}\n# Initialize Otter\nimport otter\ngrader = otter.Notebook(\"lab1.ipynb\")\n```\n:::\n\n\n![](img/571_lab_banner.png)\n\n# Lab 1: Decision trees and machine learning fundamentals\n\n<br><br>\n\n## Imports\n\n::: {#c6f10217 .cell execution_count=2}\n``` {.python .cell-code}\nfrom hashlib import sha1\n\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nfrom sklearn.dummy import DummyClassifier\nfrom sklearn.model_selection import cross_val_score, cross_validate, train_test_split\nfrom sklearn.tree import DecisionTreeClassifier\n\n# Do I need this?\nfrom sklearn import tree\n```\n:::\n\n\n<br><br>\n\n<!-- BEGIN QUESTION -->\n\n<div class=\"alert alert-info\">\n\n## Submission instructions <a name=\"si\"></a>\nrubric={mechanics}\n\nYou will receive marks for correctly submitting this assignment by following the instructions below:\n    \n- Be sure to adhere to the [general lab instructions](https://ubc-mds.github.io/resources_pages/general_lab_instructions/).\n- [Here](https://github.com/UBC-MDS/public/tree/master/rubric) you can find the description of each rubric used in MDS.\n- Make at least three commits in your lab's GitHub repository.    \n- Push the final .ipynb file containing your solutions to your GitHub repository for this lab.        \n- Before submitting your lab, run all cells in your notebook to make sure there are no errors by doing `Kernel -> Restart Kernel and Clear All Outputs` and then `Run -> Run All Cells`. Notebooks without the output displayed may not be graded at all (because we need to see the output in order to grade your work).  \n- Ensure that you are enrolled in Gradescope through [Canvas](https://canvas.ubc.ca/courses/123600).\n- Upload the .ipynb file to Gradescope and wait till your assignment to run on Gradescope.\n- Verify that your plots/output are properly rendered in Gradescope.    \n- If the .ipynb file is too large or doesn't render on Gradescope for any reason, also upload a pdf (preferably WebPDF) or html export of .ipynb file with your solutions so that TAs can view your submission on Gradescope. \n- Do not push or upload the data you download for this lab to your repository or Gradescope. (There is also a `.gitignore` in the repo to prevent this.)\n- Below this cell, include a clickable link to your GitHub repository for the lab just below this cell.\n</div>    \n\n_Points:_ 4\n\nhttps://github.ubc.ca/mds-2024-25/DSCI_571_lab1_thamerd\n\n<!-- END QUESTION -->\n\n<br><br>\n\n<div class=\"alert alert-info\">\n    \n## Worksheet section\n\n</div>\n\n## Exercise 1: Terminology\nrubric={autograde}\n\n**Your Task:**\n\nPlease fill in each of the following sentences using the provided machine learning terminologies from the list below. Keep in mind that each term should be used only once!\n\n**List of Terms (in no particular order):**\n\n    a) hyperparameters\n    b) training\n    c) tree depth\n    d) parameters\n    e) example/data point\n    f) features\n    g) target\n    h) root node\n    i) branch\n    j) leaf node\n\n    \n\n1. In the context of working with data, each individual row or instance, which includes both feature values and the corresponding target, is commonly referred to as an ________.\n\n2. In supervise machine learning, the ________ is the variable we aim to predict or understand.\n\n3. Before diving into the modeling process, it is necessary to define specific settings that impact the learning process; these settings are known as ________.\n\n4. After the model has completed the training phase, it acquires specific values, such as which features to prioritize and the threshold for splitting them in the case of decision trees; these acquired values are referred to as _________.\n   \n5. In decision trees, the initial question we ask, which serves as the starting point, is commonly referred to as the ________.\n\n6. The total number of steps or transitions from the initial question all the way to the final prediction in a decision tree is known as the ________.\n\n<div class=\"alert alert-warning\">\n\nSolution_1.1\n    \n</div>\n\n_Points:_ 3\n\n::: {#744ce962 .cell tags='[]' execution_count=3}\n``` {.python .cell-code}\n# format your answer like this: terminology = ['x','x','x','x','x','x']\nterminology = ['e','g','a','d','h','c']\n\n# 3 might be d parameters\n\n...\n```\n\n::: {.cell-output .cell-output-display execution_count=3}\n```\nEllipsis\n```\n:::\n:::\n\n\n::: {#a2e4d8b2 .cell editable='false' execution_count=4}\n``` {.python .cell-code}\ngrader.check(\"q1.1\")\n```\n\n::: {.cell-output .cell-output-display execution_count=4}\n```{=html}\n<p><strong><pre style='display: inline;'>q1.1</pre></strong> passed! 🎉</p>\n```\n:::\n:::\n\n\n<br><br>\n\n## Exercise 2: Decision trees with a toy dataset \n<hr>\n\nSuppose you have three different job offers with comparable salaries and job descriptions. You want to decide which one to accept, and you want to make this decision based on which job is likely to make you happy. Being a very systematic person, you come up with three features associated with the offers, which are important for your happiness: whether the colleagues are supportive, whether there is work-hour flexibility, and whether the company is a start-up or not. So the `X` of your offer data looks as follows: \n\n::: {#31581275 .cell execution_count=5}\n``` {.python .cell-code}\noffer_data = {\n    # Features\n    \"supportive_colleagues\": [1, 0, 0, 1],\n    \"work_hour_flexibility\": [0, 0, 1, 1],\n    \"start_up\": [0, 1, 1, 1],    \n}\n\noffer_df = pd.DataFrame(offer_data)\noffer_df\n```\n\n::: {.cell-output .cell-output-display execution_count=5}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>supportive_colleagues</th>\n      <th>work_hour_flexibility</th>\n      <th>start_up</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\nYour goal is to get predictions for these rows. In other words, for each row, you want to predict whether that job would make you **happy** or **unhappy**.   \n\nSo you ask the following questions to some of your friends (who you think have similar notions of happiness) regarding their jobs:\n\n1. Do you have supportive colleagues? (1 for 'yes' and 0 for 'no')\n2. Do you have flexible work hours? (1 for 'yes' and 0 for 'no')\n3. Do you work for a start-up? (1 for 'start up' and 0 for 'non start up')\n4. Are you happy in your job? (happy or unhappy)\n\nSuppose you get the following data from this toy survey. You decide to train a machine learning model using this toy survey data and use this model to predict which job from `offer_df` is likely to make you happy. \n\n::: {#7a1c6b7e .cell execution_count=6}\n``` {.python .cell-code}\nimport pandas as pd\n\nhappiness_data = {\n    # Features\n    \"supportive_colleagues\": [1, 1, 1, 0, 0, 1, 1, 0, 1, 0],\n    \"work_hour_flexibility\": [1, 1, 0, 1, 1, 0, 1, 0, 0, 0],\n    \"start_up\": [1, 0, 1, 0, 1, 0, 0, 1, 1, 0],\n    # Target\n    \"target\": [\n        \"happy\",\n        \"happy\",\n        \"happy\",\n        \"unhappy\",\n        \"unhappy\",\n        \"happy\",\n        \"happy\",\n        \"unhappy\",\n        \"unhappy\",\n        \"unhappy\",\n    ],\n}\n\ntrain_df = pd.DataFrame(happiness_data)\ntrain_df\n```\n\n::: {.cell-output .cell-output-display execution_count=6}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>supportive_colleagues</th>\n      <th>work_hour_flexibility</th>\n      <th>start_up</th>\n      <th>target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>happy</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>happy</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>happy</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>unhappy</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>unhappy</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>happy</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>happy</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>unhappy</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>unhappy</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>unhappy</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\n<br><br>\n\n### 2.1 Decision stump by hand \nrubric={autograde}\n\n**Your tasks:**\n\n- With this toy dataset, build a decision stump (decision tree with only 1 split) manually, splitting on the condition `supportive_colleagues <= 0.5`. What training accuracy would you get with this decision stump? Save the accuracy as a decimal in an object named `supportive_colleagues_acc`. \n\n> You do not have to show any calculations or code. \n\n<div class=\"alert alert-warning\">\n\nSolution_2.1\n    \n</div>\n\n_Points:_ 2\n\n::: {#bce6c3be .cell tags='[]' execution_count=7}\n``` {.python .cell-code}\n# x = train_df[train_df['supportive_colleagues'] <= 0.5]\n# x = train_df.drop(columns=[\"target\"])\n# y = train_df['target']\n\n# dummy_clf = DummyClassifier(strategy=\"most_frequent\")\n# dummy_clf.fit(x, y)\n\nedited_train_df = train_df.copy()\n\nedited_train_df['split'] = train_df['supportive_colleagues'] <= 0.5\nedited_train_df.loc[edited_train_df['split'] == True, 'split'] = 'unhappy'\nedited_train_df.loc[edited_train_df['split'] == False, 'split'] = 'happy'\n\nsupportive_colleagues_acc = (edited_train_df['target'] == edited_train_df['split']).sum() / edited_train_df['target'].count()\ntrain_df\nsupportive_colleagues_acc\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nC:\\Users\\Thamer\\AppData\\Local\\Temp\\ipykernel_25044\\1859072173.py:11: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'unhappy' has dtype incompatible with bool, please explicitly cast to a compatible dtype first.\n  edited_train_df.loc[edited_train_df['split'] == True, 'split'] = 'unhappy'\n```\n:::\n\n::: {.cell-output .cell-output-display execution_count=7}\n```\n0.9\n```\n:::\n:::\n\n\n::: {#94c60698 .cell editable='false' execution_count=8}\n``` {.python .cell-code}\ngrader.check(\"q2.1\")\n```\n\n::: {.cell-output .cell-output-display execution_count=8}\n```{=html}\n<p><strong><pre style='display: inline;'>q2.1</pre></strong> passed! 💯</p>\n```\n:::\n:::\n\n\n<br><br>\n\n### 2.2 Separating features and target\nrubric={autograde}\n\nRecall that in `scikit-learn`, before building a classifier, we need to separate features and target. \n\n**Your tasks:**\n\n1. Separate features and target from `train_df` and save them in `X_train_toy` and `y_train_toy`, respectively. \n\n<div class=\"alert alert-warning\">\n\nSolution_2.2\n    \n</div>\n\n_Points:_ 1\n\n::: {#fbe36463 .cell tags='[]' execution_count=9}\n``` {.python .cell-code}\nX_train_toy = train_df.drop(columns=[\"target\"])\ny_train_toy = train_df['target']\n\n...\n```\n\n::: {.cell-output .cell-output-display execution_count=9}\n```\nEllipsis\n```\n:::\n:::\n\n\n::: {#c4ad932a .cell editable='false' execution_count=10}\n``` {.python .cell-code}\ngrader.check(\"q2.2\")\n```\n\n::: {.cell-output .cell-output-display execution_count=10}\n```{=html}\n<p><strong><pre style='display: inline;'>q2.2</pre></strong> passed! 🍀</p>\n```\n:::\n:::\n\n\n<br><br>\n\n### 2.3 Create a decision tree classifier object\nrubric={autograde}\n\n**Your tasks:**\n\n1. Create a `DecisionTreeClassifier` object with `random_state=16` and store it in a variable called `toy_tree`.\n\n<div class=\"alert alert-warning\">\n\nSolution_2.3\n    \n</div>\n\n_Points:_ 1\n\n::: {#5a4d4d18 .cell tags='[]' execution_count=11}\n``` {.python .cell-code}\ntoy_tree = DecisionTreeClassifier(random_state=16)\n\n...\n```\n\n::: {.cell-output .cell-output-display execution_count=11}\n```\nEllipsis\n```\n:::\n:::\n\n\n::: {#a244d418 .cell editable='false' execution_count=12}\n``` {.python .cell-code}\ngrader.check(\"q2.3\")\n```\n\n::: {.cell-output .cell-output-display execution_count=12}\n```{=html}\n<p><strong><pre style='display: inline;'>q2.3</pre></strong> passed! 🎉</p>\n```\n:::\n:::\n\n\n<br><br>\n\n### 2.4 `fit` the decision tree classifier \nrubric={autograde}\n\n**Your tasks:**\n\n1. Now train a decision tree model by calling `fit` on `toy_tree` with `X_train_toy` and `y_train_toy` created above. \n\n<div class=\"alert alert-warning\">\n\nSolution_2.4\n    \n</div>\n\n_Points:_ 1\n\n::: {#91f1377f .cell tags='[]' execution_count=13}\n``` {.python .cell-code}\ntoy_tree.fit(X_train_toy, y_train_toy)\n```\n\n::: {.cell-output .cell-output-display execution_count=13}\n```{=html}\n<style>#sk-container-id-1 {\n  /* Definition of color scheme common for light and dark mode */\n  --sklearn-color-text: #000;\n  --sklearn-color-text-muted: #666;\n  --sklearn-color-line: gray;\n  /* Definition of color scheme for unfitted estimators */\n  --sklearn-color-unfitted-level-0: #fff5e6;\n  --sklearn-color-unfitted-level-1: #f6e4d2;\n  --sklearn-color-unfitted-level-2: #ffe0b3;\n  --sklearn-color-unfitted-level-3: chocolate;\n  /* Definition of color scheme for fitted estimators */\n  --sklearn-color-fitted-level-0: #f0f8ff;\n  --sklearn-color-fitted-level-1: #d4ebff;\n  --sklearn-color-fitted-level-2: #b3dbfd;\n  --sklearn-color-fitted-level-3: cornflowerblue;\n\n  /* Specific color for light theme */\n  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n  --sklearn-color-icon: #696969;\n\n  @media (prefers-color-scheme: dark) {\n    /* Redefinition of color scheme for dark theme */\n    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n    --sklearn-color-icon: #878787;\n  }\n}\n\n#sk-container-id-1 {\n  color: var(--sklearn-color-text);\n}\n\n#sk-container-id-1 pre {\n  padding: 0;\n}\n\n#sk-container-id-1 input.sk-hidden--visually {\n  border: 0;\n  clip: rect(1px 1px 1px 1px);\n  clip: rect(1px, 1px, 1px, 1px);\n  height: 1px;\n  margin: -1px;\n  overflow: hidden;\n  padding: 0;\n  position: absolute;\n  width: 1px;\n}\n\n#sk-container-id-1 div.sk-dashed-wrapped {\n  border: 1px dashed var(--sklearn-color-line);\n  margin: 0 0.4em 0.5em 0.4em;\n  box-sizing: border-box;\n  padding-bottom: 0.4em;\n  background-color: var(--sklearn-color-background);\n}\n\n#sk-container-id-1 div.sk-container {\n  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n     but bootstrap.min.css set `[hidden] { display: none !important; }`\n     so we also need the `!important` here to be able to override the\n     default hidden behavior on the sphinx rendered scikit-learn.org.\n     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n  display: inline-block !important;\n  position: relative;\n}\n\n#sk-container-id-1 div.sk-text-repr-fallback {\n  display: none;\n}\n\ndiv.sk-parallel-item,\ndiv.sk-serial,\ndiv.sk-item {\n  /* draw centered vertical line to link estimators */\n  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n  background-size: 2px 100%;\n  background-repeat: no-repeat;\n  background-position: center center;\n}\n\n/* Parallel-specific style estimator block */\n\n#sk-container-id-1 div.sk-parallel-item::after {\n  content: \"\";\n  width: 100%;\n  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n  flex-grow: 1;\n}\n\n#sk-container-id-1 div.sk-parallel {\n  display: flex;\n  align-items: stretch;\n  justify-content: center;\n  background-color: var(--sklearn-color-background);\n  position: relative;\n}\n\n#sk-container-id-1 div.sk-parallel-item {\n  display: flex;\n  flex-direction: column;\n}\n\n#sk-container-id-1 div.sk-parallel-item:first-child::after {\n  align-self: flex-end;\n  width: 50%;\n}\n\n#sk-container-id-1 div.sk-parallel-item:last-child::after {\n  align-self: flex-start;\n  width: 50%;\n}\n\n#sk-container-id-1 div.sk-parallel-item:only-child::after {\n  width: 0;\n}\n\n/* Serial-specific style estimator block */\n\n#sk-container-id-1 div.sk-serial {\n  display: flex;\n  flex-direction: column;\n  align-items: center;\n  background-color: var(--sklearn-color-background);\n  padding-right: 1em;\n  padding-left: 1em;\n}\n\n\n/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\nclickable and can be expanded/collapsed.\n- Pipeline and ColumnTransformer use this feature and define the default style\n- Estimators will overwrite some part of the style using the `sk-estimator` class\n*/\n\n/* Pipeline and ColumnTransformer style (default) */\n\n#sk-container-id-1 div.sk-toggleable {\n  /* Default theme specific background. It is overwritten whether we have a\n  specific estimator or a Pipeline/ColumnTransformer */\n  background-color: var(--sklearn-color-background);\n}\n\n/* Toggleable label */\n#sk-container-id-1 label.sk-toggleable__label {\n  cursor: pointer;\n  display: flex;\n  width: 100%;\n  margin-bottom: 0;\n  padding: 0.5em;\n  box-sizing: border-box;\n  text-align: center;\n  align-items: start;\n  justify-content: space-between;\n  gap: 0.5em;\n}\n\n#sk-container-id-1 label.sk-toggleable__label .caption {\n  font-size: 0.6rem;\n  font-weight: lighter;\n  color: var(--sklearn-color-text-muted);\n}\n\n#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n  /* Arrow on the left of the label */\n  content: \"▸\";\n  float: left;\n  margin-right: 0.25em;\n  color: var(--sklearn-color-icon);\n}\n\n#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n  color: var(--sklearn-color-text);\n}\n\n/* Toggleable content - dropdown */\n\n#sk-container-id-1 div.sk-toggleable__content {\n  max-height: 0;\n  max-width: 0;\n  overflow: hidden;\n  text-align: left;\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-0);\n}\n\n#sk-container-id-1 div.sk-toggleable__content.fitted {\n  /* fitted */\n  background-color: var(--sklearn-color-fitted-level-0);\n}\n\n#sk-container-id-1 div.sk-toggleable__content pre {\n  margin: 0.2em;\n  border-radius: 0.25em;\n  color: var(--sklearn-color-text);\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-0);\n}\n\n#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n  /* unfitted */\n  background-color: var(--sklearn-color-fitted-level-0);\n}\n\n#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n  /* Expand drop-down */\n  max-height: 200px;\n  max-width: 100%;\n  overflow: auto;\n}\n\n#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n  content: \"▾\";\n}\n\n/* Pipeline/ColumnTransformer-specific style */\n\n#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n  color: var(--sklearn-color-text);\n  background-color: var(--sklearn-color-unfitted-level-2);\n}\n\n#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n  background-color: var(--sklearn-color-fitted-level-2);\n}\n\n/* Estimator-specific style */\n\n/* Colorize estimator box */\n#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-2);\n}\n\n#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n  /* fitted */\n  background-color: var(--sklearn-color-fitted-level-2);\n}\n\n#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n#sk-container-id-1 div.sk-label label {\n  /* The background is the default theme color */\n  color: var(--sklearn-color-text-on-default-background);\n}\n\n/* On hover, darken the color of the background */\n#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n  color: var(--sklearn-color-text);\n  background-color: var(--sklearn-color-unfitted-level-2);\n}\n\n/* Label box, darken color on hover, fitted */\n#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n  color: var(--sklearn-color-text);\n  background-color: var(--sklearn-color-fitted-level-2);\n}\n\n/* Estimator label */\n\n#sk-container-id-1 div.sk-label label {\n  font-family: monospace;\n  font-weight: bold;\n  display: inline-block;\n  line-height: 1.2em;\n}\n\n#sk-container-id-1 div.sk-label-container {\n  text-align: center;\n}\n\n/* Estimator-specific */\n#sk-container-id-1 div.sk-estimator {\n  font-family: monospace;\n  border: 1px dotted var(--sklearn-color-border-box);\n  border-radius: 0.25em;\n  box-sizing: border-box;\n  margin-bottom: 0.5em;\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-0);\n}\n\n#sk-container-id-1 div.sk-estimator.fitted {\n  /* fitted */\n  background-color: var(--sklearn-color-fitted-level-0);\n}\n\n/* on hover */\n#sk-container-id-1 div.sk-estimator:hover {\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-2);\n}\n\n#sk-container-id-1 div.sk-estimator.fitted:hover {\n  /* fitted */\n  background-color: var(--sklearn-color-fitted-level-2);\n}\n\n/* Specification for estimator info (e.g. \"i\" and \"?\") */\n\n/* Common style for \"i\" and \"?\" */\n\n.sk-estimator-doc-link,\na:link.sk-estimator-doc-link,\na:visited.sk-estimator-doc-link {\n  float: right;\n  font-size: smaller;\n  line-height: 1em;\n  font-family: monospace;\n  background-color: var(--sklearn-color-background);\n  border-radius: 1em;\n  height: 1em;\n  width: 1em;\n  text-decoration: none !important;\n  margin-left: 0.5em;\n  text-align: center;\n  /* unfitted */\n  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n  color: var(--sklearn-color-unfitted-level-1);\n}\n\n.sk-estimator-doc-link.fitted,\na:link.sk-estimator-doc-link.fitted,\na:visited.sk-estimator-doc-link.fitted {\n  /* fitted */\n  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n  color: var(--sklearn-color-fitted-level-1);\n}\n\n/* On hover */\ndiv.sk-estimator:hover .sk-estimator-doc-link:hover,\n.sk-estimator-doc-link:hover,\ndiv.sk-label-container:hover .sk-estimator-doc-link:hover,\n.sk-estimator-doc-link:hover {\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-3);\n  color: var(--sklearn-color-background);\n  text-decoration: none;\n}\n\ndiv.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n.sk-estimator-doc-link.fitted:hover,\ndiv.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n.sk-estimator-doc-link.fitted:hover {\n  /* fitted */\n  background-color: var(--sklearn-color-fitted-level-3);\n  color: var(--sklearn-color-background);\n  text-decoration: none;\n}\n\n/* Span, style for the box shown on hovering the info icon */\n.sk-estimator-doc-link span {\n  display: none;\n  z-index: 9999;\n  position: relative;\n  font-weight: normal;\n  right: .2ex;\n  padding: .5ex;\n  margin: .5ex;\n  width: min-content;\n  min-width: 20ex;\n  max-width: 50ex;\n  color: var(--sklearn-color-text);\n  box-shadow: 2pt 2pt 4pt #999;\n  /* unfitted */\n  background: var(--sklearn-color-unfitted-level-0);\n  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n}\n\n.sk-estimator-doc-link.fitted span {\n  /* fitted */\n  background: var(--sklearn-color-fitted-level-0);\n  border: var(--sklearn-color-fitted-level-3);\n}\n\n.sk-estimator-doc-link:hover span {\n  display: block;\n}\n\n/* \"?\"-specific style due to the `<a>` HTML tag */\n\n#sk-container-id-1 a.estimator_doc_link {\n  float: right;\n  font-size: 1rem;\n  line-height: 1em;\n  font-family: monospace;\n  background-color: var(--sklearn-color-background);\n  border-radius: 1rem;\n  height: 1rem;\n  width: 1rem;\n  text-decoration: none;\n  /* unfitted */\n  color: var(--sklearn-color-unfitted-level-1);\n  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n}\n\n#sk-container-id-1 a.estimator_doc_link.fitted {\n  /* fitted */\n  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n  color: var(--sklearn-color-fitted-level-1);\n}\n\n/* On hover */\n#sk-container-id-1 a.estimator_doc_link:hover {\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-3);\n  color: var(--sklearn-color-background);\n  text-decoration: none;\n}\n\n#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n  /* fitted */\n  background-color: var(--sklearn-color-fitted-level-3);\n}\n</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeClassifier(random_state=16)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>DecisionTreeClassifier</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.tree.DecisionTreeClassifier.html\">?<span>Documentation for DecisionTreeClassifier</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>DecisionTreeClassifier(random_state=16)</pre></div> </div></div></div></div>\n```\n:::\n:::\n\n\n::: {#7bc314b9 .cell editable='false' execution_count=14}\n``` {.python .cell-code}\ngrader.check(\"q2.4\")\n```\n\n::: {.cell-output .cell-output-display execution_count=14}\n```{=html}\n<p><strong><pre style='display: inline;'>q2.4</pre></strong> passed! 🚀</p>\n```\n:::\n:::\n\n\n<br><br>\n\n### 2.5 Visualize the trained decision tree\nrubric={autograde}\n\n\n**Your tasks:**\n- Visualize the trained decision tree model using the [`tree.plot_tree`](https://scikit-learn.org/stable/modules/generated/sklearn.tree.plot_tree.html) method in `sklearn` by passing the appropriate values for the following arguments: \n    - `feature_names`\n    - `class_names`\n  \nSave the names of the features in `feature_names` variable, names of the classes in `class_names` variable and the visualization tree returned by the function in a variable called `toy_tree_viz`.\n\n<div class=\"alert alert-warning\">\n\nSolution_2.5\n    \n</div>\n\n_Points:_ 2\n\n::: {#4cdc9b22 .cell tags='[]' execution_count=15}\n``` {.python .cell-code}\nfeature_names = X_train_toy.columns.tolist() # feature names \nclass_names = [\"happy\", \"unhappy\"] # unique class names \n\ntoy_tree_viz = tree.plot_tree(toy_tree, feature_names=feature_names, class_names=class_names)\n```\n\n::: {.cell-output .cell-output-display}\n![](lab1_files/figure-html/cell-16-output-1.png){width=540 height=389}\n:::\n:::\n\n\n::: {#3eba4a30 .cell editable='false' execution_count=16}\n``` {.python .cell-code}\ngrader.check(\"q2.5\")\n```\n\n::: {.cell-output .cell-output-display execution_count=16}\n```{=html}\n<p><strong><pre style='display: inline;'>q2.5</pre></strong> passed! 🎉</p>\n```\n:::\n:::\n\n\n<br><br>\n\n### 2.6 Depth of the tree\nrubric={autograde}\n\n**Your tasks:**\n\n1. What's the depth of the learned decision tree model? Save it as an integer in the variable `toy_depth` below. \n\n<div class=\"alert alert-warning\">\n\nSolution_2.6\n    \n</div>\n\n_Points:_ 1\n\n::: {#4dcc6ca0 .cell tags='[]' execution_count=17}\n``` {.python .cell-code}\ntoy_depth = 3\n```\n:::\n\n\n::: {#36a0b4b2 .cell editable='false' execution_count=18}\n``` {.python .cell-code}\ngrader.check(\"q2.6\")\n```\n\n::: {.cell-output .cell-output-display execution_count=18}\n```{=html}\n<p><strong><pre style='display: inline;'>q2.6</pre></strong> passed! 🚀</p>\n```\n:::\n:::\n\n\n<br><br>\n\n### 2.7 Accuracy calculation\nrubric={autograde}\n\n**Your tasks:**\n\n1. Evaluate the `toy_tree` on the training data (i.e., call `score()` on `X_train_toy` and `y_train_toy`) and store the score in a variable called `train_acc`.\n\n<div class=\"alert alert-warning\">\n\nSolution_2.7\n    \n</div>\n\n_Points:_ 1\n\n::: {#73672e69 .cell tags='[]' execution_count=19}\n``` {.python .cell-code}\ntrain_acc = toy_tree.score(X_train_toy, y_train_toy)\ntrain_acc\n```\n\n::: {.cell-output .cell-output-display execution_count=19}\n```\n0.9\n```\n:::\n:::\n\n\n::: {#28c3e6ca .cell editable='false' execution_count=20}\n``` {.python .cell-code}\ngrader.check(\"q2.7\")\n```\n\n::: {.cell-output .cell-output-display execution_count=20}\n```{=html}\n<p><strong><pre style='display: inline;'>q2.7</pre></strong> passed! 💯</p>\n```\n:::\n:::\n\n\n<br><br>\n\n<!-- BEGIN QUESTION -->\n\n### 2.8 Discussion\nrubric={reasoning}\n\n**Your tasks:**\n\n1. Do you achieve perfect training accuracy? If so, what are the reasons behind this, and if not, what factors contribute to the imperfection?\n\n<div class=\"alert alert-warning\">\n\nSolution_2.8\n    \n</div>\n\n_Points:_ 2\n\nThe accuracy achieved was 0.9 which is very good but not perfect. The reason behind this is that there are 2 friends with the same inputs (2 and 8. Have supportive colleagues, don't have hour flexibility, is a start up) and yet they have different outputs: One is happy and the other is unhappy.\nThe data was collected by simply asking people about how they feel and people's feelings are very complex and are affected by much more than the 3 features we have assigned.\n\n<!-- END QUESTION -->\n\n<br><br>\n\n### 2.9 Predicting on the offer data \nrubric={autograde}\n\n**Your tasks:**\n\n1. Using the trained decision tree above, predict the targets for all examples in `offer_df` and store them as a list in the `predictions` variable below.\n2. In which jobs you are likely to be happy? Append the index or indices of all the examples where you are likely to be happy to the 'happy_job_indices' list below.\n\n::: {#76aac6b4 .cell editable='false' execution_count=21}\n``` {.python .cell-code}\noffer_df\n```\n\n::: {.cell-output .cell-output-display execution_count=21}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>supportive_colleagues</th>\n      <th>work_hour_flexibility</th>\n      <th>start_up</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\n<div class=\"alert alert-warning\">\n\nSolution_2.9\n    \n</div>\n\n_Points:_ 3\n\n::: {#ee2b6d67 .cell tags='[]' execution_count=22}\n``` {.python .cell-code}\npredictions = [list(toy_tree.predict(offer_df))][0]\nhappy_job_indices = [0,3]\n\npredictions\n```\n\n::: {.cell-output .cell-output-display execution_count=22}\n```\n['happy', 'unhappy', 'unhappy', 'happy']\n```\n:::\n:::\n\n\n::: {#6d04498e .cell editable='false' execution_count=23}\n``` {.python .cell-code}\ngrader.check(\"q2.9\")\n```\n\n::: {.cell-output .cell-output-display execution_count=23}\n```{=html}\n<p><strong><pre style='display: inline;'>q2.9</pre></strong> passed! 🙌</p>\n```\n:::\n:::\n\n\n<br><br><br><br>\n\n<div class=\"alert alert-info\">\n    \n## LAB Section\n\n</div>\n\n## Exercise 3: Decision trees on Spotify Song Attributes dataset \n<hr>\n\n### Introducing the dataset\n \nFor the rest of the lab you'll be using Kaggle's [Spotify Song Attributes](https://www.kaggle.com/geomack/spotifyclassification/home) dataset. The dataset contains a number of features of songs from 2017 and a binary variable `target` that represents whether the user liked the song (encoded as 1) or not (encoded as 0). See the documentation of all the features [here](https://developer.spotify.com/documentation/web-api/reference/get-audio-features). \n\nThis dataset is publicly available on Kaggle, and you will have to download it yourself. Follow the steps below to get the data CSV. \n\n1. If you do not have an account with [Kaggle](https://www.kaggle.com/), you will first need to create one (it's free).\n2. Login to your account and [download](https://www.kaggle.com/geomack/spotifyclassification/download) the dataset.\n3. Unzip the data file if needed, then rename it to `spotify.csv`, and move it under the `data` directory.\n\n> You will not be able to push it to your repository (hopefully) because I have seeded the repository with `.gitignore`. \n\n### 3.1 Reading the data CSV\nrubric={autograde}\n \n**Your tasks:**\n1. Read in the data CSV and store it as a pandas dataframe named `spotify_df`. The first column of the .csv file should be set as the index.\n\n> Make sure you have put the data CSV as `spotify.csv` under the data directory (data/spotify.csv). When you read the data file, use this relative path for the autograder to work properly on Gradescope. \n\n<div class=\"alert alert-warning\">\n\nSolution_3.1\n    \n</div>\n\n_Points:_ 2\n\n::: {#e8ad22db .cell nbgrader='{\"grade\":true,\"grade_id\":\"cell-4f3f14b59fd7e6b8\",\"locked\":false,\"points\":0,\"schema_version\":3,\"solution\":true,\"task\":false}' tags='[]' execution_count=24}\n``` {.python .cell-code}\nspotify_df = pd.read_csv(\"data/spotify.csv\", index_col=0)\n\nspotify_df\n```\n\n::: {.cell-output .cell-output-display execution_count=24}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>acousticness</th>\n      <th>danceability</th>\n      <th>duration_ms</th>\n      <th>energy</th>\n      <th>instrumentalness</th>\n      <th>key</th>\n      <th>liveness</th>\n      <th>loudness</th>\n      <th>mode</th>\n      <th>speechiness</th>\n      <th>tempo</th>\n      <th>time_signature</th>\n      <th>valence</th>\n      <th>target</th>\n      <th>song_title</th>\n      <th>artist</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.01020</td>\n      <td>0.833</td>\n      <td>204600</td>\n      <td>0.434</td>\n      <td>0.021900</td>\n      <td>2</td>\n      <td>0.1650</td>\n      <td>-8.795</td>\n      <td>1</td>\n      <td>0.4310</td>\n      <td>150.062</td>\n      <td>4.0</td>\n      <td>0.286</td>\n      <td>1</td>\n      <td>Mask Off</td>\n      <td>Future</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.19900</td>\n      <td>0.743</td>\n      <td>326933</td>\n      <td>0.359</td>\n      <td>0.006110</td>\n      <td>1</td>\n      <td>0.1370</td>\n      <td>-10.401</td>\n      <td>1</td>\n      <td>0.0794</td>\n      <td>160.083</td>\n      <td>4.0</td>\n      <td>0.588</td>\n      <td>1</td>\n      <td>Redbone</td>\n      <td>Childish Gambino</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.03440</td>\n      <td>0.838</td>\n      <td>185707</td>\n      <td>0.412</td>\n      <td>0.000234</td>\n      <td>2</td>\n      <td>0.1590</td>\n      <td>-7.148</td>\n      <td>1</td>\n      <td>0.2890</td>\n      <td>75.044</td>\n      <td>4.0</td>\n      <td>0.173</td>\n      <td>1</td>\n      <td>Xanny Family</td>\n      <td>Future</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.60400</td>\n      <td>0.494</td>\n      <td>199413</td>\n      <td>0.338</td>\n      <td>0.510000</td>\n      <td>5</td>\n      <td>0.0922</td>\n      <td>-15.236</td>\n      <td>1</td>\n      <td>0.0261</td>\n      <td>86.468</td>\n      <td>4.0</td>\n      <td>0.230</td>\n      <td>1</td>\n      <td>Master Of None</td>\n      <td>Beach House</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.18000</td>\n      <td>0.678</td>\n      <td>392893</td>\n      <td>0.561</td>\n      <td>0.512000</td>\n      <td>5</td>\n      <td>0.4390</td>\n      <td>-11.648</td>\n      <td>0</td>\n      <td>0.0694</td>\n      <td>174.004</td>\n      <td>4.0</td>\n      <td>0.904</td>\n      <td>1</td>\n      <td>Parallel Lines</td>\n      <td>Junior Boys</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>2012</th>\n      <td>0.00106</td>\n      <td>0.584</td>\n      <td>274404</td>\n      <td>0.932</td>\n      <td>0.002690</td>\n      <td>1</td>\n      <td>0.1290</td>\n      <td>-3.501</td>\n      <td>1</td>\n      <td>0.3330</td>\n      <td>74.976</td>\n      <td>4.0</td>\n      <td>0.211</td>\n      <td>0</td>\n      <td>Like A Bitch - Kill The Noise Remix</td>\n      <td>Kill The Noise</td>\n    </tr>\n    <tr>\n      <th>2013</th>\n      <td>0.08770</td>\n      <td>0.894</td>\n      <td>182182</td>\n      <td>0.892</td>\n      <td>0.001670</td>\n      <td>1</td>\n      <td>0.0528</td>\n      <td>-2.663</td>\n      <td>1</td>\n      <td>0.1310</td>\n      <td>110.041</td>\n      <td>4.0</td>\n      <td>0.867</td>\n      <td>0</td>\n      <td>Candy</td>\n      <td>Dillon Francis</td>\n    </tr>\n    <tr>\n      <th>2014</th>\n      <td>0.00857</td>\n      <td>0.637</td>\n      <td>207200</td>\n      <td>0.935</td>\n      <td>0.003990</td>\n      <td>0</td>\n      <td>0.2140</td>\n      <td>-2.467</td>\n      <td>1</td>\n      <td>0.1070</td>\n      <td>150.082</td>\n      <td>4.0</td>\n      <td>0.470</td>\n      <td>0</td>\n      <td>Habit - Dack Janiels &amp; Wenzday Remix</td>\n      <td>Rain Man</td>\n    </tr>\n    <tr>\n      <th>2015</th>\n      <td>0.00164</td>\n      <td>0.557</td>\n      <td>185600</td>\n      <td>0.992</td>\n      <td>0.677000</td>\n      <td>1</td>\n      <td>0.0913</td>\n      <td>-2.735</td>\n      <td>1</td>\n      <td>0.1330</td>\n      <td>150.011</td>\n      <td>4.0</td>\n      <td>0.623</td>\n      <td>0</td>\n      <td>First Contact</td>\n      <td>Twin Moons</td>\n    </tr>\n    <tr>\n      <th>2016</th>\n      <td>0.00281</td>\n      <td>0.446</td>\n      <td>204520</td>\n      <td>0.915</td>\n      <td>0.000039</td>\n      <td>9</td>\n      <td>0.2180</td>\n      <td>-6.221</td>\n      <td>1</td>\n      <td>0.1410</td>\n      <td>190.013</td>\n      <td>4.0</td>\n      <td>0.402</td>\n      <td>0</td>\n      <td>I Wanna Get Better</td>\n      <td>Bleachers</td>\n    </tr>\n  </tbody>\n</table>\n<p>2017 rows × 16 columns</p>\n</div>\n```\n:::\n:::\n\n\n::: {#746959b9 .cell editable='false' execution_count=25}\n``` {.python .cell-code}\ngrader.check(\"q3.1\")\n```\n\n::: {.cell-output .cell-output-display execution_count=25}\n```{=html}\n<p><strong><pre style='display: inline;'>q3.1</pre></strong> passed! 💯</p>\n```\n:::\n:::\n\n\n<br><br>\n\n### 3.2 Data splitting \nrubric={autograde\n\n**Your tasks:**\n\n1. Split the dataframe into `train_df` and `test_df` with `random_state=123` and `test_size=0.2`. \n\n<div class=\"alert alert-warning\">\n\nSolution_3.2\n    \n</div>\n\n_Points:_ 2\n\n::: {#762eefa0 .cell tags='[]' execution_count=26}\n``` {.python .cell-code}\ntrain_df = None\ntest_df = None\n\ntrain_df, test_df = train_test_split(\n    spotify_df, test_size=0.2, random_state=123\n)\n```\n:::\n\n\n::: {#5653297a .cell editable='false' execution_count=27}\n``` {.python .cell-code}\ngrader.check(\"q3.2\")\n```\n\n::: {.cell-output .cell-output-display execution_count=27}\n```{=html}\n<p><strong><pre style='display: inline;'>q3.2</pre></strong> passed! 💯</p>\n```\n:::\n:::\n\n\n<br><br>\n\n### 3.3 Number of training and test examples\nrubric={autograde}\n\n**Your tasks:**\n1. How many training and test examples do we have? Store them as integers in the variables below. \n\n<div class=\"alert alert-warning\">\n\nSolution_3.3\n    \n</div>\n\n_Points:_ 1\n\n::: {#77ec3ca3 .cell tags='[]' execution_count=28}\n``` {.python .cell-code}\n# Please provide integer values\nn_train_samples = train_df.shape[0]\nn_test_samples = test_df.shape[0]\n\nprint(n_train_samples)\nprint(n_test_samples)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n1613\n404\n```\n:::\n:::\n\n\n::: {#5b0973f4 .cell editable='false' execution_count=29}\n``` {.python .cell-code}\ngrader.check(\"q3.3\")\n```\n\n::: {.cell-output .cell-output-display execution_count=29}\n```{=html}\n<p><strong><pre style='display: inline;'>q3.3</pre></strong> passed! 🍀</p>\n```\n:::\n:::\n\n\n<br><br>\n\n### 3.4 `describe` method \nrubric={autograde}\n\n**Your tasks:**\n\n1. Store the output of `describe()` **on the training split** in `spotify_summary` variable below and display the summary statistics. By default, this function will compute some summary statistics of the numeric columns.\n\n> Note that `describe` returns another DataFrame.\n\n<div class=\"alert alert-warning\">\n\nSolution_3.4\n    \n</div>\n\n_Points:_ 2\n\n::: {#6079efdb .cell tags='[]' execution_count=30}\n``` {.python .cell-code}\nspotify_summary = train_df.describe()\nspotify_summary\n```\n\n::: {.cell-output .cell-output-display execution_count=30}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>acousticness</th>\n      <th>danceability</th>\n      <th>duration_ms</th>\n      <th>energy</th>\n      <th>instrumentalness</th>\n      <th>key</th>\n      <th>liveness</th>\n      <th>loudness</th>\n      <th>mode</th>\n      <th>speechiness</th>\n      <th>tempo</th>\n      <th>time_signature</th>\n      <th>valence</th>\n      <th>target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>1613.000000</td>\n      <td>1613.000000</td>\n      <td>1613.000000</td>\n      <td>1613.000000</td>\n      <td>1613.000000</td>\n      <td>1613.000000</td>\n      <td>1613.000000</td>\n      <td>1613.000000</td>\n      <td>1613.000000</td>\n      <td>1613.000000</td>\n      <td>1613.000000</td>\n      <td>1613.000000</td>\n      <td>1613.000000</td>\n      <td>1613.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>0.185627</td>\n      <td>0.616745</td>\n      <td>247114.827650</td>\n      <td>0.681296</td>\n      <td>0.136862</td>\n      <td>5.383137</td>\n      <td>0.189189</td>\n      <td>-7.112929</td>\n      <td>0.621203</td>\n      <td>0.091277</td>\n      <td>121.979777</td>\n      <td>3.964662</td>\n      <td>0.497587</td>\n      <td>0.507750</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>0.259324</td>\n      <td>0.163225</td>\n      <td>81177.300308</td>\n      <td>0.211612</td>\n      <td>0.277744</td>\n      <td>3.620422</td>\n      <td>0.153170</td>\n      <td>3.838867</td>\n      <td>0.485238</td>\n      <td>0.087890</td>\n      <td>26.965641</td>\n      <td>0.255201</td>\n      <td>0.247378</td>\n      <td>0.500095</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>0.000005</td>\n      <td>0.122000</td>\n      <td>16042.000000</td>\n      <td>0.014800</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.018800</td>\n      <td>-33.097000</td>\n      <td>0.000000</td>\n      <td>0.023100</td>\n      <td>47.859000</td>\n      <td>1.000000</td>\n      <td>0.035900</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>0.009190</td>\n      <td>0.511000</td>\n      <td>200105.000000</td>\n      <td>0.564000</td>\n      <td>0.000000</td>\n      <td>2.000000</td>\n      <td>0.092300</td>\n      <td>-8.388000</td>\n      <td>0.000000</td>\n      <td>0.037300</td>\n      <td>100.518000</td>\n      <td>4.000000</td>\n      <td>0.295000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>0.062500</td>\n      <td>0.629000</td>\n      <td>230200.000000</td>\n      <td>0.714000</td>\n      <td>0.000071</td>\n      <td>6.000000</td>\n      <td>0.127000</td>\n      <td>-6.248000</td>\n      <td>1.000000</td>\n      <td>0.054900</td>\n      <td>121.990000</td>\n      <td>4.000000</td>\n      <td>0.496000</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>0.251000</td>\n      <td>0.738000</td>\n      <td>272533.000000</td>\n      <td>0.844000</td>\n      <td>0.057300</td>\n      <td>9.000000</td>\n      <td>0.243000</td>\n      <td>-4.791000</td>\n      <td>1.000000</td>\n      <td>0.107000</td>\n      <td>137.932000</td>\n      <td>4.000000</td>\n      <td>0.690000</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>0.995000</td>\n      <td>0.984000</td>\n      <td>849960.000000</td>\n      <td>0.997000</td>\n      <td>0.976000</td>\n      <td>11.000000</td>\n      <td>0.969000</td>\n      <td>-0.307000</td>\n      <td>1.000000</td>\n      <td>0.816000</td>\n      <td>219.331000</td>\n      <td>5.000000</td>\n      <td>0.992000</td>\n      <td>1.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\n::: {#5f460306 .cell editable='false' execution_count=31}\n``` {.python .cell-code}\ngrader.check(\"q3.4\")\n```\n\n::: {.cell-output .cell-output-display execution_count=31}\n```{=html}\n<p><strong><pre style='display: inline;'>q3.4</pre></strong> passed! 🙌</p>\n```\n:::\n:::\n\n\n<br><br>\n\n### 3.5 Largest range feature\nrubric={autograde}\n\n**Your tasks:**\n\n1. Which feature has the largest range? Store the feature name as a string in the `largest_range_feature` variable below.\n\n> Hint: You can subtract the min value from the max value of the column to get the range.\n\n<div class=\"alert alert-warning\">\n\nSolution_3.5\n    \n</div>\n\n_Points:_ 2\n\n::: {#47c38dcb .cell tags='[]' execution_count=32}\n``` {.python .cell-code}\nlargest_range_feature = 'duration_ms'\n\n...\n```\n\n::: {.cell-output .cell-output-display execution_count=32}\n```\nEllipsis\n```\n:::\n:::\n\n\n::: {#8fd847f4 .cell editable='false' execution_count=33}\n``` {.python .cell-code}\ngrader.check(\"q3.5\")\n```\n\n::: {.cell-output .cell-output-display execution_count=33}\n```{=html}\n<p><strong><pre style='display: inline;'>q3.5</pre></strong> passed! ✨</p>\n```\n:::\n:::\n\n\n<br><br>\n\n<!-- BEGIN QUESTION -->\n\n### 3.6 Plotting histograms \nrubric={viz}\n\nThe starter code below produces histograms for the `loudness` feature using pandas plotting. The histograms show the distribution of the feature values in the training set, separated for positive (target=1, i.e., user liked the song) and negative (target=0, i.e., user disliked the song) examples. There are two different histograms, one for target = 0 and one for target = 1, and they are overlaid on top of each other. The histogram shows that extremely quiet songs tend to be disliked (more blue bars than orange on the left) and very loud songs also tend to be disliked (more blue than orange on the far right).\n\n> Note: I am using `matplotlib` and pandas plotting here. This is a manually graded question and you can use altair instead, as you're learning it in DSCI 531. I've added `altair` in the course environment and it'll also work fine on Gradescope. \n\n::: {#868422ee .cell editable='false' metadata='{\"tags\":[\"otter_ignore\"]}' slideshow='{\"slide_type\":\"\"}' tags='[]' execution_count=34}\n``` {.python .cell-code}\nfeat = \"loudness\"\ntrain_df.groupby(\"target\")[feat].plot.hist(bins=50, alpha=0.5, legend=True, density = True, title = \"Histogram of \" + feat);\nplt.xlabel(feat);\n```\n\n::: {.cell-output .cell-output-display}\n![](lab1_files/figure-html/cell-35-output-1.png){width=606 height=449}\n:::\n:::\n\n\n**Your tasks:**\n\nCreate histograms for the following features in the order below.\n- acousticness\n- danceability\n- tempo\n- energy\n- valence\n\n> To adhere to the [DRY (Don't Repeat Yourself)](https://en.wikipedia.org/wiki/Don%27t_repeat_yourself) principle, make sure you use a `for` loop for your plotting, rather than repeating the plotting code 4 times. For this to work, I used `plt.show()` at the end of your loop, which draws the figure and resets the canvas for your next plot.\n\n<div class=\"alert alert-warning\">\n\nSolution_3.6\n    \n</div>\n\n_Points:_ 3\n\n::: {#7ea6abd5 .cell editable='true' metadata='{\"tags\":[\"otter_ignore\"]}' slideshow='{\"slide_type\":\"\"}' tags='[]' execution_count=35}\n``` {.python .cell-code}\nfor feat in ['acousticness', 'danceability', 'tempo', 'energy', 'valence']:\n    train_df.groupby(\"target\")[feat].plot.hist(bins=50, alpha=0.5, legend=True, density = True, title = \"Histogram of \" + feat);\n    plt.xlabel(feat);\n    plt.show()\n\n```\n\n::: {.cell-output .cell-output-display}\n![](lab1_files/figure-html/cell-36-output-1.png){width=597 height=449}\n:::\n\n::: {.cell-output .cell-output-display}\n![](lab1_files/figure-html/cell-36-output-2.png){width=589 height=449}\n:::\n\n::: {.cell-output .cell-output-display}\n![](lab1_files/figure-html/cell-36-output-3.png){width=611 height=449}\n:::\n\n::: {.cell-output .cell-output-display}\n![](lab1_files/figure-html/cell-36-output-4.png){width=589 height=449}\n:::\n\n::: {.cell-output .cell-output-display}\n![](lab1_files/figure-html/cell-36-output-5.png){width=597 height=449}\n:::\n:::\n\n\n<!-- END QUESTION -->\n\n<br><br>\n\n<!-- BEGIN QUESTION -->\n\n### 3.7 Identical histograms\nrubric={reasoning}\n\n**Your tasks:**\n\n1. Let's say that, for a particular feature, the histograms of that feature are identical for the two target classes. Does that mean the feature is not useful for predicting the target class? Briefly explain. \n\n<div class=\"alert alert-warning\">\n\nSolution_3.7\n    \n</div>\n\n_Points:_ 2\n\nIf the histograms of a particular feature are identical for the target classes, that suggests that it has no impact on the target. Which means it is not useful for predicting the target.\n\n<!-- END QUESTION -->\n\n<br><br>\n\n<!-- BEGIN QUESTION -->\n\n### 3.8 Which columns to include? \nrubric={reasoning}\n\nNote that the dataset includes two text features labeled `song_title` and `artist`.\n\n**Your tasks:**\n\n1. Do you believe that these features could be valuable in predicting whether the user liked the song or not? If so, what makes them suitable, and if not, what makes them unsuitable?\n2. Do you anticipate any challenges in using these features in their current form within your model? Please provide a brief explanation. \n\n<div class=\"alert alert-warning\">\n\nSolution_3.8\n    \n</div>\n\n_Points:_ 4\n\n1. For the song title, I think it will be mostly irrelevant for our predictions as it is arbitrary and generally doesn't affect a person's opinion on the song. However, I do believe the artist does affect a person's opinion on the song as some artists are much more widely loved than others.\n2. The main challenge is that the artist column contains strings instead of numeric values.\n\n<!-- END QUESTION -->\n\n<br><br><br><br>\n\n## Exercise 4: Model building\n<hr>\n\nNow that we did some preliminary exploratory data analysis (EDA), let's move on to modeling. \n\n<br><br>\n\n### 4.1 Creating `X` and `y`\nrubric={autograde}\n\n**Your tasks:**\n\n1. Separate `X` and `y` from `train_df` and `test_df` from the previous exercise and store them as `X_train`, `y_train`, `X_test`, `y_test`, respectively. Skip the `song_title` and `artist` columns for now. \n\n<div class=\"alert alert-warning\">\n\nSolution_4.1\n    \n</div>\n\n_Points:_ 2\n\n::: {#d31c23ee .cell editable='true' slideshow='{\"slide_type\":\"\"}' tags='[]' execution_count=36}\n``` {.python .cell-code}\nX_train = train_df.drop(columns=['target', 'song_title', 'artist'])\ny_train = train_df['target']\nX_test = test_df.drop(columns=['target', 'song_title', 'artist'])\ny_test = test_df['target']\n\n# X_train_toy = train_df.drop(columns=[\"target\"])\n# y_train_toy = train_df['target']\n```\n:::\n\n\n::: {#89167797 .cell editable='false' execution_count=37}\n``` {.python .cell-code}\ngrader.check(\"q4.1\")\n```\n\n::: {.cell-output .cell-output-display execution_count=37}\n```{=html}\n<p><strong><pre style='display: inline;'>q4.1</pre></strong> passed! ✨</p>\n```\n:::\n:::\n\n\n<br><br>\n\n<br><br>\n\n### 4.2 The baseline model: `DummyClassifier`\nrubric={autograde}\n\n**Your tasks:**\n1. Carry out 10-fold cross-validation using `DummyClassifier` with `random_state=123`. Store the mean cross-validation score in the `dummy_score` variable below. \n\n<div class=\"alert alert-warning\">\n\nSolution_4.2\n    \n</div>\n\n_Points:_ 1\n\n::: {#5bd6b8af .cell editable='true' slideshow='{\"slide_type\":\"\"}' tags='[]' execution_count=38}\n``` {.python .cell-code}\ndum = DummyClassifier(random_state=123)\ndummy_score = np.mean(cross_val_score(dum, X_train, y_train, cv=10))\ndummy_score\n```\n\n::: {.cell-output .cell-output-display execution_count=38}\n```\n0.5077524729698643\n```\n:::\n:::\n\n\n::: {#71457e75 .cell editable='false' execution_count=39}\n``` {.python .cell-code}\ngrader.check(\"q4.2\")\n```\n\n::: {.cell-output .cell-output-display execution_count=39}\n```{=html}\n<p><strong><pre style='display: inline;'>q4.2</pre></strong> passed! 🙌</p>\n```\n:::\n:::\n\n\n<br><br>\n\n### 4.3 Creating a Decision Tree model\nrubric={autograde}\n\n**Your tasks:**\n\n1. Create a `DecisionTreeClassifier` with `random_state=123` and store it in a variable called `spotify_tree`.\n\n<div class=\"alert alert-warning\">\n\nSolution_4.3\n    \n</div>\n\n_Points:_ 1\n\n::: {#5f872aea .cell editable='true' slideshow='{\"slide_type\":\"\"}' tags='[]' execution_count=40}\n``` {.python .cell-code}\nspotify_tree = DecisionTreeClassifier(random_state=123)\n```\n:::\n\n\n::: {#b379e8ef .cell editable='false' execution_count=41}\n``` {.python .cell-code}\ngrader.check(\"q4.3\")\n```\n\n::: {.cell-output .cell-output-display execution_count=41}\n```{=html}\n<p><strong><pre style='display: inline;'>q4.3</pre></strong> passed! 💯</p>\n```\n:::\n:::\n\n\n<br><br>\n\n### 4.4 Cross-validation with `DecisionTreeClassifier`\nrubric={autograde}\n\n**Your tasks:** \n\n1. Carry out 10-fold cross validation with the `spotify_tree` object above using `cross_validate` on `X_train` and `y_train`. Pass `return_train_score=True` to `cross_validate`. Save the results as a pandas dataframe in a variable called `dt_scores_df`. \n\n<div class=\"alert alert-warning\">\n\nSolution_4.4\n    \n</div>\n\n_Points:_ 4\n\n::: {#9ce2928c .cell editable='true' slideshow='{\"slide_type\":\"\"}' tags='[]' execution_count=42}\n``` {.python .cell-code}\ndt_scores_df = pd.DataFrame(cross_validate(spotify_tree, X_train, y_train, cv=10, return_train_score=True))\ndt_scores_df\n```\n\n::: {.cell-output .cell-output-display execution_count=42}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>fit_time</th>\n      <th>score_time</th>\n      <th>test_score</th>\n      <th>train_score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.010113</td>\n      <td>0.000997</td>\n      <td>0.697531</td>\n      <td>0.999311</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.011059</td>\n      <td>0.001000</td>\n      <td>0.660494</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.011096</td>\n      <td>0.001999</td>\n      <td>0.685185</td>\n      <td>0.999311</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.014150</td>\n      <td>0.001000</td>\n      <td>0.639752</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.012088</td>\n      <td>0.001004</td>\n      <td>0.639752</td>\n      <td>0.999311</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>0.010091</td>\n      <td>0.001000</td>\n      <td>0.658385</td>\n      <td>0.999311</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>0.010387</td>\n      <td>0.001086</td>\n      <td>0.639752</td>\n      <td>0.999311</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>0.010325</td>\n      <td>0.001004</td>\n      <td>0.608696</td>\n      <td>0.999311</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>0.011058</td>\n      <td>0.000000</td>\n      <td>0.701863</td>\n      <td>0.999311</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>0.013152</td>\n      <td>0.001000</td>\n      <td>0.695652</td>\n      <td>0.999311</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\n::: {#e2c4fc1f .cell execution_count=43}\n``` {.python .cell-code}\nround(dt_scores_df['test_score'].mean(), 3)\n```\n\n::: {.cell-output .cell-output-display execution_count=43}\n```\n0.663\n```\n:::\n:::\n\n\n::: {#7c37510e .cell editable='false' execution_count=44}\n``` {.python .cell-code}\ngrader.check(\"q4.4\")\n```\n\n::: {.cell-output .cell-output-display execution_count=44}\n```{=html}\n<p><strong style='color: red;'><pre style='display: inline;'>q4.4</pre> results:</strong></p><p><strong><pre style='display: inline;'>q4.4 - 1</pre> result:</strong></p><pre>    ✅ Test case passed</pre><p><strong><pre style='display: inline;'>q4.4 - 2</pre> result:</strong></p><pre>    ✅ Test case passed</pre><p><strong><pre style='display: inline;'>q4.4 - 3</pre> result:</strong></p><pre>    ❌ Test case failed\n    Trying:\n        assert np.isclose(round(dt_scores_df['test_score'].mean(), 3), 0.671), 'Your test scores are incorrect'\n    Expecting nothing\n    **********************************************************************\n    Line 1, in q4.4 2\n    Failed example:\n        assert np.isclose(round(dt_scores_df['test_score'].mean(), 3), 0.671), 'Your test scores are incorrect'\n    Exception raised:\n        Traceback (most recent call last):\n          File \"C:\\Users\\Thamer\\miniforge3\\Lib\\doctest.py\", line 1368, in __run\n            exec(compile(example.source, filename, \"single\",\n          File \"<doctest q4.4 2[0]>\", line 1, in <module>\n            assert np.isclose(round(dt_scores_df['test_score'].mean(), 3), 0.671), 'Your test scores are incorrect'\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n        AssertionError: Your test scores are incorrect\n    Trying:\n        assert np.isclose(round(dt_scores_df['train_score'].mean(), 3), 0.999), 'Your train scores are incorrect'\n    Expecting nothing\n    ok\n</pre>\n```\n:::\n:::\n\n\n<br><br>\n\n<!-- BEGIN QUESTION -->\n\n### 4.5 Examining cross-validation scores\nrubric={reasoning}\n\n**Your tasks:** \n1. Inspect the 10 sub-scores from the 10 folds of cross-validation. To what extent do you trust the numerical value / precision of the cross validation score? Briefly explain.  \n2. Do you see a significant difference between the training scores and the cross-validation scores? Briefly discuss in 1 to 2 sentences. \n\n<div class=\"alert alert-warning\">\n\nSolution_4.5\n    \n</div>\n\n_Points:_ 4\n\n_Type your answer here, replacing this text._\n\nThe minimum test score we got was 0.608696 and the max is 0.722222 which shows a somewhat significant variance in our test score which is not great but not terrible either. \n\nThe training scores are nearly perfect whereas the test scores range from ~0.6 to ~0.7 which is a big difference and suggests that our model is overfitting the training data. \n\n<!-- END QUESTION -->\n\n<br><br><br><br>\n\n## Exercise 5: Hyperparameters\n<hr>\n\nIn this exercise, you'll experiment with the `max_depth` hyperparameter of the decision tree classifier. See the [`DecisionTreeClassifier` documentation](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html) for more details.\n\n### 5.1 Train and cross-validation accuracies \nrubric={autograde}\n\n\n**Your tasks:**\n\n1. Explore the `max_depth` hyperparameter. Run 10-fold cross-validation for trees with the following values of `max_depth`: `np.arange(1, 25, 2)`. Set the `random_state` of `DecisionTreeClassifier` to 123 in each case for reproducibility. \n2. For each `max_depth`, get both the mean train accuracy and the mean cross-validation accuracy. Store your results in the `results_df` dataframe, where the max_depth is set as the index. \n\n> Note: generally speaking (for all assignments) you are welcome to copy/paste code directly from the lecture notes, though I ask that you add a small citation (e.g. \"Adapted from lecture 1\") if you do so.\n\n::: {#177725b5 .cell editable='false' execution_count=45}\n``` {.python .cell-code}\ndepths = np.arange(1, 25, 2)\ndepths\n```\n\n::: {.cell-output .cell-output-display execution_count=45}\n```\narray([ 1,  3,  5,  7,  9, 11, 13, 15, 17, 19, 21, 23])\n```\n:::\n:::\n\n\n<div class=\"alert alert-warning\">\n\nSolution_5.1\n    \n</div>\n\n_Points:_ 6\n\n::: {#9f28636d .cell tags='[]' execution_count=46}\n``` {.python .cell-code}\n# Adapted and adjusted from lecture 2\n\nresults_dict = {\n    \"depth\": [],\n    \"mean_train_score\": [],\n    \"mean_cv_score\": [],\n}\n\nfor depth in depths:\n    model = DecisionTreeClassifier(max_depth=depth, random_state=123)\n    scores = cross_validate(model, X_train, y_train, cv=10, return_train_score=True)\n    results_dict[\"depth\"].append(depth)\n    results_dict[\"mean_cv_score\"].append(np.mean(scores[\"test_score\"]))\n    results_dict[\"mean_train_score\"].append(np.mean(scores[\"train_score\"]))\n\nresults_df = pd.DataFrame(results_dict)\nresults_df = results_df.set_index(\"depth\")\n```\n:::\n\n\n::: {#69f3a13c .cell tags='[]' execution_count=47}\n``` {.python .cell-code}\nresults_df\n```\n\n::: {.cell-output .cell-output-display execution_count=47}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>mean_train_score</th>\n      <th>mean_cv_score</th>\n    </tr>\n    <tr>\n      <th>depth</th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>0.651030</td>\n      <td>0.646032</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.733485</td>\n      <td>0.692524</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>0.794035</td>\n      <td>0.711713</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>0.858718</td>\n      <td>0.703060</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>0.912930</td>\n      <td>0.690610</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>0.955157</td>\n      <td>0.680048</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>0.980850</td>\n      <td>0.674457</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>0.993525</td>\n      <td>0.658979</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>0.998278</td>\n      <td>0.669538</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>0.999173</td>\n      <td>0.665812</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>0.999449</td>\n      <td>0.662706</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>0.999449</td>\n      <td>0.662706</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\n::: {#5f061bf5 .cell tags='[]' execution_count=48}\n``` {.python .cell-code}\nresults_df.shape\n```\n\n::: {.cell-output .cell-output-display execution_count=48}\n```\n(12, 2)\n```\n:::\n:::\n\n\n::: {#efef9c06 .cell editable='false' execution_count=49}\n``` {.python .cell-code}\ngrader.check(\"q5.1\")\n```\n\n::: {.cell-output .cell-output-display execution_count=49}\n```{=html}\n<p><strong><pre style='display: inline;'>q5.1</pre></strong> passed! 💯</p>\n```\n:::\n:::\n\n\n<br><br>\n\n<!-- BEGIN QUESTION -->\n\n### 5.2 Visualization \nrubric={viz}\n\n1. Make a plot with `max_depth` on the *x*-axis and the train and cross-validation accuracies on the *y*-axis. That is, your plot should have two curves, one for train and one for cross-validation. \n\n**Ensure your plot includes the following:**\n\n1. Both the train accuracy and the cross-validation accuracy are included in the plot.\n2. Include a legend to specify which is which. \n3. The provided `max_depth` values are used.\n4. The x-axis and y-axis have reasonable names.\n5. The data points are correct.\n\n<div class=\"alert alert-warning\">\n\nSolution_5.2\n    \n</div>\n\n_Points:_ 5\n\n::: {#55889cbd .cell editable='true' slideshow='{\"slide_type\":\"\"}' tags='[]' execution_count=50}\n``` {.python .cell-code}\nresults_df[[\"mean_train_score\", \"mean_cv_score\"]].plot()\n```\n\n::: {.cell-output .cell-output-display}\n![](lab1_files/figure-html/cell-51-output-1.png){width=579 height=429}\n:::\n:::\n\n\n<!-- END QUESTION -->\n\n<br><br>\n\n<!-- BEGIN QUESTION -->\n\n### 5.3 `max_depth` and the fundamental tradeoff\nrubric={reasoning}\n\n**Your tasks:**\n1. Discuss how changing the `max_depth` hyperparameter affects the training and cross-validation accuracy. \n\n<div class=\"alert alert-warning\">\n\nSolution_5.3\n    \n</div>\n\n_Points:_ 3\n\nAt max depth < 5 we seem to be underfitting because we are not training enough. Whereas at max depth > 5 we approach overfitting because we are relying too much on our training data. I believe the sweet spot is at max depth = 5\n\n<!-- END QUESTION -->\n\n<br><br>\n\n### 5.4 Picking the \"best\" value for `max_depth`\nrubric={autograde}\n\n**Your tasks:**\n1. From these results, pick the \"best\" `max_depth`, the one which gives the maximum cross-validation score. Store it in a variable called `best_max_depth` as an integer. \n\n<div class=\"alert alert-warning\">\n\nSolution_5.4\n    \n</div>\n\n_Points:_ 2\n\n::: {#442bfa14 .cell tags='[]' execution_count=51}\n``` {.python .cell-code}\nbest_max_depth = 5\n\n...\n```\n\n::: {.cell-output .cell-output-display execution_count=51}\n```\nEllipsis\n```\n:::\n:::\n\n\n::: {#a4d738d7 .cell editable='false' execution_count=52}\n``` {.python .cell-code}\ngrader.check(\"q5.4\")\n```\n\n::: {.cell-output .cell-output-display execution_count=52}\n```{=html}\n<p><strong><pre style='display: inline;'>q5.4</pre></strong> passed! 🙌</p>\n```\n:::\n:::\n\n\n<br><br>\n\n### 5.5 Final assessment on the test split \nrubric={autograde}\n\nNow that we have our finalized model, we are ready to evaluate it on the test set. \n\n**Your tasks:**\n\n1. Create a decision tree model `best_model` using the `best_max_depth` you chose in the previous exercise. \n2. Fit the `best_model` on the _entire training set_ (`X_train` and `y_train`). \n2. Compute the test score (on `X_test` and `y_test`) and store it in a variable called `test_score` below. \n\n<div class=\"alert alert-warning\">\n\nSolution_5.5\n    \n</div>\n\n_Points:_ 3\n\n::: {#4c7d260c .cell tags='[]' execution_count=53}\n``` {.python .cell-code}\nbest_model = DecisionTreeClassifier(max_depth=5, random_state=123)\nbest_model.fit(X_test, y_test)\ntest_score = best_model.score(X_test, y_test)\ntest_score\n```\n\n::: {.cell-output .cell-output-display execution_count=53}\n```\n0.8267326732673267\n```\n:::\n:::\n\n\n<br><br>\n\n<!-- BEGIN QUESTION -->\n\n### 5.6 Analysis\nrubric={reasoning}\n\n**Your tasks:**\n\n1. How do the test scores compare to the cross-validation scores? Briefly discuss. \n2. Why can't you simply pick the value of `max_depth` that gives the best accuracy on the training data? (Answer in maximum 2 to 3 sentences.)\n3. Do you think that the `max_depth` you chose would generalize to other \"spotify\" datasets (i.e., data on other spotify users)?\n\n<div class=\"alert alert-warning\">\n\nSolution_5.6\n    \n</div>\n\n_Points:_ 6\n\n1. Our best model's test score was ~0.8 whereas the cross-validation scores were ranging from ~0.6 to ~0.7.\n2. Because if we choose the best max_depth for the training data we may end up overfitting and performing poorly on new unseen data.\n3. It could but it might not. Different data sets will have different characteristics which may impact the best max depth. Ideally we should test our model on different datasets to validate it.\n\n<!-- END QUESTION -->\n\n<br><br><br><br>\n\n## Exercise 6: Food for thought\n<hr>\n\nEach lab will have a few challenging questions. In some of the labs I will be including challenging questions which lead to the material in the upcoming week. These are usually low-risk questions and will contribute to maximum 5% of the lab grade. The main purpose here is to challenge yourself or dig deeper in a particular area. When you start working on labs, attempt all other questions before moving to these challenging questions. If you are running out of time, please skip the challenging questions. \n\n![](img/eva-game-on.png)\n\n<!-- BEGIN QUESTION -->\n\n### (Challenging) 6.1 The index column in the spotify dataset\nrubric={reasoning}\n\n**Your tasks:**\n\n1. In Exercise 3.1, I explicitly asked you to set the first column as the index column. What would happen if you would not have set it as an index column and treat that column as one of the features? What would be train and test accuracies in that case? Be clear and thorough in your answer.  \n\n<div class=\"alert alert-warning\">\n\nSolution_6.1\n    \n</div>\n\n_Points:_ 1\n\nIf we do not explicitly set an index column, an extra index column will be added automatically which may or may not be desired. In our case we don't need it as we already have a suitable index column.\n\n<!-- END QUESTION -->\n\n<br><br>\n\n<!-- BEGIN QUESTION -->\n\n### (Challenging) 6.2 Shuffling\nrubric={reasoning}\n\nBy default, `train_test_split()` function shuffles the data before splitting. \n\n**Your tasks:**\n1. What would be the consequences of splitting the data without shuffling it and using this unshuffled data in modeling?\n2. Examine whether shuffling the data improves the CV scores and test score in the Spotify dataset.\n\n<div class=\"alert alert-warning\">\n\nSolution_6.2\n    \n</div>\n\n_Points:_ 1\n\n1. Without shuffling, we will more likely run into issues such as overfitting or underfitting, bias, and poor generalization.\n2. As we can see below, the CV scores are nearly identical between the shuffled and unshuffled models. However, the shuffled model had a much better test score of ~0.8 vs the unshuffled model's ~0.7.\n\n::: {#d1152f28 .cell execution_count=54}\n``` {.python .cell-code}\ntrain_df2, test_df2 = train_test_split(spotify_df, test_size=0.2, random_state=123, shuffle=False)\n\nX_train2 = train_df2.drop(columns=['target', 'song_title', 'artist'])\ny_train2 = train_df2['target']\nX_test2 = test_df2.drop(columns=['target', 'song_title', 'artist'])\ny_test2 = test_df2['target']\n\nunshuffled_model = DecisionTreeClassifier(max_depth=5, random_state=123)\nunshuffled_model.fit(X_train, y_train)\nunshuffled_cv_score = np.mean(cross_val_score(unshuffled_model, X_train2, y_train2, cv=10))\nunshuffled_test_score = unshuffled_model.score(X_test2, y_test2)\n\nprint('shuffled CV score:',results_df['mean_cv_score'][5])\nprint('Shuffled test score:',test_score)\n\n\nprint('Unshuffled CV score:',unshuffled_cv_score)\nprint('Unshuffled test score:',unshuffled_test_score)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nshuffled CV score: 0.7117130588145081\nShuffled test score: 0.8267326732673267\nUnshuffled CV score: 0.7148186488766198\nUnshuffled test score: 0.8341584158415841\n```\n:::\n:::\n\n\n<!-- END QUESTION -->\n\n<br><br>\n\n<!-- BEGIN QUESTION -->\n\n### (Challenging) 6.3 Exploring datasets and features\nrubric={reasoning}\n\nIn Exercise 5.1, you systematically searched for a model using cross-validation that is likely to generalize well . \n\n**Your tasks:**\n\nProvide thoughtful answers to the following questions:\n1. Does this model use all the features provided to it? Which features appear to be the most important, and does this align with what you observed during exploratory data analysis? Please briefly explain.\n2. In this assignment, we are considering all numeric features. However, are the \"key,\" \"mode,\" and \"time_signature\" features actually numeric? You can check the documentation of these features [here](https://developer.spotify.com/documentation/web-api/reference/get-audio-features).\n3. It's worth noting that the \"acousticness\" and \"duration_ms\" features are on entirely different scales. Does this difference in scale matter when we train a `DecisionTreeClassifier`? Please briefly explain.\n4. Suppose you believe that the \"artist\" is a valuable feature for this task. How would you encode it in order to use it with `sklearn`?\n\n<div class=\"alert alert-warning\">\n\nSolution_6.3\n    \n</div>\n\n_Points:_ 2\n\n1. Our model uses all of the provided features except for the song title and artist. Danceability and Valence seem to the most important features which does align with our EDA as we can see in the histograms.\n2. Key denotes the musical key the the song is in. It is translated from musical key notes into integers. Mode is translated from major or minor into 1 or 0. time_signature is translated from the musical notation into an estimated integer.\n3. It does not matter as long as the scale is consistent between our observations in the training and test datasets as each feature's values will be evaluated against other observations within the same feature and scale.\n4. I would assign a unique integer to each artist. This will allow our model to differentiate between widely loved artist and highly criticized artists. \n\n<!-- END QUESTION -->\n\n<br><br><br><br>\n\n**Before submitting your assignment, please make sure you have followed all the instructions in the Submission Instructions section at the top.**\n\nCongratulations on finishing lab 1! Well done 👏👏! \n\n![](img/eva-well-done.png)\n\n",
    "supporting": [
      "lab1_files"
    ],
    "filters": [],
    "includes": {
      "include-in-header": [
        "<script src=\"https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js\" integrity=\"sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==\" crossorigin=\"anonymous\"></script>\n<script src=\"https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js\" integrity=\"sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==\" crossorigin=\"anonymous\" data-relocate-top=\"true\"></script>\n<script type=\"application/javascript\">define('jquery', [],function() {return window.jQuery;})</script>\n"
      ]
    }
  }
}
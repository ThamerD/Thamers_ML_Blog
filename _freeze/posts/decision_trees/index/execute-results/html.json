{
  "hash": "bc3658d7d7a6671697424102dcaa11d5",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: 'Machine Learning Models: Decision Trees'\njupyter: python3\ncategories: [ML Model, Guide, Code, Analysis]\nimage: \"cover.png\"\ntoc: true\ntoc-depth: 2\n---\n\n\nOn this page, we explore Decision Trees and showcase one of their use cases.\n\n\n## Imports\n\n::: {#15eb745e .cell execution_count=1}\n``` {.python .cell-code}\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nfrom sklearn.dummy import DummyClassifier\nfrom sklearn.model_selection import cross_val_score, cross_validate, train_test_split\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn import tree\n```\n:::\n\n\nWe'll be using Kaggle's [Spotify Song Attributes](https://www.kaggle.com/geomack/spotifyclassification/home) dataset. The dataset contains a number of features of songs from 2017 and a binary variable `target` that represents whether the user liked the song (encoded as 1) or not (encoded as 0). See the documentation of all the features [here](https://developer.spotify.com/documentation/web-api/reference/get-audio-features). \n\n## 1. Read and split the dataset\n<hr>\n\n- We use `read_csv` from the pandas package to read the data.  \n- We use `train_test_split` from sklearn to split the data into separate training and test sets. (Not to be confused with validation sets which will be created later from the training set).  \n  - The `test_size` parameter determines the proportion of the test set to the training set. Generally, a larger training set results in a better model, a larger test set results in a more accurate assessment of the model. We must find a balance between these two.\n  - Note that the dataset is sorted on the target. If we maintain this list sorting our model will simply predict the target based on the song's position in the sorted list, rather than its features. This will not help us make predictions for future unseen data. Therefore, we set the first column as the index so that our model does not learn the sorted order of our data.\n\n::: {#f57c2f7f .cell nbgrader='{\"grade\":true,\"grade_id\":\"cell-4f3f14b59fd7e6b8\",\"locked\":false,\"points\":0,\"schema_version\":3,\"solution\":true,\"task\":false}' tags='[]' execution_count=2}\n``` {.python .cell-code}\nspotify_df = pd.read_csv(\"data/spotify.csv\", index_col=0)\n\nspotify_df.head() # to show a sample from the dataset\n```\n\n::: {.cell-output .cell-output-display execution_count=2}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>acousticness</th>\n      <th>danceability</th>\n      <th>duration_ms</th>\n      <th>energy</th>\n      <th>instrumentalness</th>\n      <th>key</th>\n      <th>liveness</th>\n      <th>loudness</th>\n      <th>mode</th>\n      <th>speechiness</th>\n      <th>tempo</th>\n      <th>time_signature</th>\n      <th>valence</th>\n      <th>target</th>\n      <th>song_title</th>\n      <th>artist</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.0102</td>\n      <td>0.833</td>\n      <td>204600</td>\n      <td>0.434</td>\n      <td>0.021900</td>\n      <td>2</td>\n      <td>0.1650</td>\n      <td>-8.795</td>\n      <td>1</td>\n      <td>0.4310</td>\n      <td>150.062</td>\n      <td>4.0</td>\n      <td>0.286</td>\n      <td>1</td>\n      <td>Mask Off</td>\n      <td>Future</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.1990</td>\n      <td>0.743</td>\n      <td>326933</td>\n      <td>0.359</td>\n      <td>0.006110</td>\n      <td>1</td>\n      <td>0.1370</td>\n      <td>-10.401</td>\n      <td>1</td>\n      <td>0.0794</td>\n      <td>160.083</td>\n      <td>4.0</td>\n      <td>0.588</td>\n      <td>1</td>\n      <td>Redbone</td>\n      <td>Childish Gambino</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.0344</td>\n      <td>0.838</td>\n      <td>185707</td>\n      <td>0.412</td>\n      <td>0.000234</td>\n      <td>2</td>\n      <td>0.1590</td>\n      <td>-7.148</td>\n      <td>1</td>\n      <td>0.2890</td>\n      <td>75.044</td>\n      <td>4.0</td>\n      <td>0.173</td>\n      <td>1</td>\n      <td>Xanny Family</td>\n      <td>Future</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.6040</td>\n      <td>0.494</td>\n      <td>199413</td>\n      <td>0.338</td>\n      <td>0.510000</td>\n      <td>5</td>\n      <td>0.0922</td>\n      <td>-15.236</td>\n      <td>1</td>\n      <td>0.0261</td>\n      <td>86.468</td>\n      <td>4.0</td>\n      <td>0.230</td>\n      <td>1</td>\n      <td>Master Of None</td>\n      <td>Beach House</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.1800</td>\n      <td>0.678</td>\n      <td>392893</td>\n      <td>0.561</td>\n      <td>0.512000</td>\n      <td>5</td>\n      <td>0.4390</td>\n      <td>-11.648</td>\n      <td>0</td>\n      <td>0.0694</td>\n      <td>174.004</td>\n      <td>4.0</td>\n      <td>0.904</td>\n      <td>1</td>\n      <td>Parallel Lines</td>\n      <td>Junior Boys</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\n::: {#92a58c57 .cell tags='[]' execution_count=3}\n``` {.python .cell-code}\ntrain_df = None\ntest_df = None\n\ntrain_df, test_df = train_test_split(\n    spotify_df, test_size=0.2, random_state=123\n)\n```\n:::\n\n\n## 2. Exploratory Data Analysis (EDA)\nIn this section, we want to take a closer look at the dataset so that we can make more informed decisions when designing the model later.\n<hr>\n\n::: {#2a773ddc .cell tags='[]' execution_count=4}\n``` {.python .cell-code}\nn_train_samples = train_df.shape[0]\nn_test_samples = test_df.shape[0]\n\nprint(f\"Number of training samples: {n_train_samples}\")\nprint(f\"Number of test samples: {n_test_samples}\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nNumber of training samples: 1613\nNumber of test samples: 404\n```\n:::\n:::\n\n\n::: {#e186c21c .cell tags='[]' execution_count=5}\n``` {.python .cell-code}\nspotify_summary = train_df.describe()\nspotify_summary\n```\n\n::: {.cell-output .cell-output-display execution_count=5}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>acousticness</th>\n      <th>danceability</th>\n      <th>duration_ms</th>\n      <th>energy</th>\n      <th>instrumentalness</th>\n      <th>key</th>\n      <th>liveness</th>\n      <th>loudness</th>\n      <th>mode</th>\n      <th>speechiness</th>\n      <th>tempo</th>\n      <th>time_signature</th>\n      <th>valence</th>\n      <th>target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>1613.000000</td>\n      <td>1613.000000</td>\n      <td>1613.000000</td>\n      <td>1613.000000</td>\n      <td>1613.000000</td>\n      <td>1613.000000</td>\n      <td>1613.000000</td>\n      <td>1613.000000</td>\n      <td>1613.000000</td>\n      <td>1613.000000</td>\n      <td>1613.000000</td>\n      <td>1613.000000</td>\n      <td>1613.000000</td>\n      <td>1613.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>0.185627</td>\n      <td>0.616745</td>\n      <td>247114.827650</td>\n      <td>0.681296</td>\n      <td>0.136862</td>\n      <td>5.383137</td>\n      <td>0.189189</td>\n      <td>-7.112929</td>\n      <td>0.621203</td>\n      <td>0.091277</td>\n      <td>121.979777</td>\n      <td>3.964662</td>\n      <td>0.497587</td>\n      <td>0.507750</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>0.259324</td>\n      <td>0.163225</td>\n      <td>81177.300308</td>\n      <td>0.211612</td>\n      <td>0.277744</td>\n      <td>3.620422</td>\n      <td>0.153170</td>\n      <td>3.838867</td>\n      <td>0.485238</td>\n      <td>0.087890</td>\n      <td>26.965641</td>\n      <td>0.255201</td>\n      <td>0.247378</td>\n      <td>0.500095</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>0.000005</td>\n      <td>0.122000</td>\n      <td>16042.000000</td>\n      <td>0.014800</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.018800</td>\n      <td>-33.097000</td>\n      <td>0.000000</td>\n      <td>0.023100</td>\n      <td>47.859000</td>\n      <td>1.000000</td>\n      <td>0.035900</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>0.009190</td>\n      <td>0.511000</td>\n      <td>200105.000000</td>\n      <td>0.564000</td>\n      <td>0.000000</td>\n      <td>2.000000</td>\n      <td>0.092300</td>\n      <td>-8.388000</td>\n      <td>0.000000</td>\n      <td>0.037300</td>\n      <td>100.518000</td>\n      <td>4.000000</td>\n      <td>0.295000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>0.062500</td>\n      <td>0.629000</td>\n      <td>230200.000000</td>\n      <td>0.714000</td>\n      <td>0.000071</td>\n      <td>6.000000</td>\n      <td>0.127000</td>\n      <td>-6.248000</td>\n      <td>1.000000</td>\n      <td>0.054900</td>\n      <td>121.990000</td>\n      <td>4.000000</td>\n      <td>0.496000</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>0.251000</td>\n      <td>0.738000</td>\n      <td>272533.000000</td>\n      <td>0.844000</td>\n      <td>0.057300</td>\n      <td>9.000000</td>\n      <td>0.243000</td>\n      <td>-4.791000</td>\n      <td>1.000000</td>\n      <td>0.107000</td>\n      <td>137.932000</td>\n      <td>4.000000</td>\n      <td>0.690000</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>0.995000</td>\n      <td>0.984000</td>\n      <td>849960.000000</td>\n      <td>0.997000</td>\n      <td>0.976000</td>\n      <td>11.000000</td>\n      <td>0.969000</td>\n      <td>-0.307000</td>\n      <td>1.000000</td>\n      <td>0.816000</td>\n      <td>219.331000</td>\n      <td>5.000000</td>\n      <td>0.992000</td>\n      <td>1.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\nIn the following plots, we explore different features and analyze their relationship with our target. 1 means the user liked the song, 0 means they did not.\n\n::: {#35d0cc0a .cell editable='false' metadata='{\"tags\":[\"otter_ignore\"]}' slideshow='{\"slide_type\":\"\"}' tags='[]' execution_count=6}\n``` {.python .cell-code}\n# Histogram for loudness\nfeat = \"loudness\"\ntrain_df.groupby(\"target\")[feat].plot.hist(bins=50, alpha=0.5, legend=True, density = True, title = \"Histogram of \" + feat)\nplt.xlabel(feat)\n```\n\n::: {.cell-output .cell-output-display execution_count=6}\n```\nText(0.5, 0, 'loudness')\n```\n:::\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/cell-7-output-2.png){width=606 height=449}\n:::\n:::\n\n\n::: {#cdb72f9d .cell editable='true' metadata='{\"tags\":[\"otter_ignore\"]}' slideshow='{\"slide_type\":\"\"}' tags='[]' execution_count=7}\n``` {.python .cell-code}\nfor feat in ['acousticness', 'danceability', 'tempo', 'energy', 'valence']: # This loop creates a histogram for each of the features in the list\n    train_df.groupby(\"target\")[feat].plot.hist(bins=50, alpha=0.5, legend=True, density = True, title = \"Histogram of \" + feat)\n    plt.xlabel(feat)\n    plt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/cell-8-output-1.png){width=597 height=449}\n:::\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/cell-8-output-2.png){width=589 height=449}\n:::\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/cell-8-output-3.png){width=611 height=449}\n:::\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/cell-8-output-4.png){width=589 height=449}\n:::\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/cell-8-output-5.png){width=597 height=449}\n:::\n:::\n\n\nKeep in mind that even if we see a feature with a histogram that has not discernable patterns with the target, it does not necessarily mean that the feature is not useful for predicting the target. As some patterns only appear when a feature is combined with another. For example: Valence on its own seems insignificant for predicting the target, but that can change when we look at Valence alongside Tempo.\n\nNote that the dataset includes two text features labeled `song_title` and `artist`. For now, we will simply drop these text features as encoding text can be tricky and may derail us from our original goal here, which is to explore decision trees.\n\n## 3. Select features\n<hr>\n\nIn this section, we select the features we want our model to learn. In our case, we will take all the available features except for `song_title` and `artist`. Note that we also need to split our x and y (features and target respectively).\n\n::: {#6e734966 .cell editable='true' slideshow='{\"slide_type\":\"\"}' tags='[]' execution_count=8}\n``` {.python .cell-code}\nX_train = train_df.drop(columns=['target', 'song_title', 'artist'])\ny_train = train_df['target']\nX_test = test_df.drop(columns=['target', 'song_title', 'artist'])\ny_test = test_df['target']\n```\n:::\n\n\n## 4. Create and assess the baseline\n<hr>\n\nIn this section, we create a very simple baseline model which we will use to measure our decision tree model against. In our case, the `DummyClassifier` will simply predict the most frequent case. Meaning if most songs in our dataset were liked, it will predict that they were all liked.  \nWe then use cross_val_score to assess our baseline model.\n\n::: {#8a4438c0 .cell editable='true' slideshow='{\"slide_type\":\"\"}' tags='[]' execution_count=9}\n``` {.python .cell-code}\ndum = DummyClassifier(random_state=123, strategy='most_frequent')\ndummy_score = np.mean(cross_val_score(dum, X_train, y_train, cv=10))\ndummy_score\n```\n\n::: {.cell-output .cell-output-display execution_count=9}\n```\n0.5077524729698643\n```\n:::\n:::\n\n\n## 5. Create and assess the Decision Tree model\n<hr>\n\nIn this section, we finally create the decision tree model, and we assess it using `cross_validate`. Note that this function fits the model to the dataset as its first step so we don't need to fit our model beforehand.\n\n::: {#7bcd9ad1 .cell editable='true' slideshow='{\"slide_type\":\"\"}' tags='[]' execution_count=10}\n``` {.python .cell-code}\nspotify_tree = DecisionTreeClassifier(random_state=123)\n```\n:::\n\n\n::: {#60a39839 .cell editable='true' slideshow='{\"slide_type\":\"\"}' tags='[]' execution_count=11}\n``` {.python .cell-code}\ndt_scores_df = pd.DataFrame(cross_validate(spotify_tree, X_train, y_train, cv=10, return_train_score=True))\ndt_scores_df\n```\n\n::: {.cell-output .cell-output-display execution_count=11}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>fit_time</th>\n      <th>score_time</th>\n      <th>test_score</th>\n      <th>train_score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.012000</td>\n      <td>0.000999</td>\n      <td>0.697531</td>\n      <td>0.999311</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.011036</td>\n      <td>0.001000</td>\n      <td>0.660494</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.010537</td>\n      <td>0.001000</td>\n      <td>0.685185</td>\n      <td>0.999311</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.011002</td>\n      <td>0.000000</td>\n      <td>0.639752</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.009505</td>\n      <td>0.001000</td>\n      <td>0.639752</td>\n      <td>0.999311</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>0.009999</td>\n      <td>0.001000</td>\n      <td>0.658385</td>\n      <td>0.999311</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>0.010000</td>\n      <td>0.001000</td>\n      <td>0.639752</td>\n      <td>0.999311</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>0.011000</td>\n      <td>0.001000</td>\n      <td>0.608696</td>\n      <td>0.999311</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>0.010999</td>\n      <td>0.001002</td>\n      <td>0.701863</td>\n      <td>0.999311</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>0.011001</td>\n      <td>0.000999</td>\n      <td>0.695652</td>\n      <td>0.999311</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\nThe main number we want to look at here is `test_score`. We ran 10 different tests on our model, let's take their mean value and compare it to our baseline.\n\n::: {#f1b1fa61 .cell execution_count=12}\n``` {.python .cell-code}\nround(dt_scores_df['test_score'].mean(), 3)\n```\n\n::: {.cell-output .cell-output-display execution_count=12}\n```\n0.663\n```\n:::\n:::\n\n\n## 6. (Optional) Visualize the model\n<hr>\n\nIn this section, we use the `tree` package to visualize our decision tree model to understand it better\n\n::: {#84cb4c0b .cell execution_count=13}\n``` {.python .cell-code}\nspotify_tree.fit(X_train, y_train) # We must fit (train) the model before we visualize it\n\nfeature_names = X_train.columns.tolist() # feature names \nclass_names = [\"Liked\", \"Disliked\"] # unique class names \n\ntoy_tree_viz = tree.plot_tree(spotify_tree, feature_names=feature_names, class_names=class_names, max_depth=1)\n# The tree is too big and complicated to fully visualize, so we set max_depth=2 to visualize the first layers only\n```\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/cell-14-output-1.png){width=540 height=389}\n:::\n:::\n\n\n## 6. Hyperparameter optimization\n<hr>\n\nSo far, we have used the decision tree model in its default configuration and got some decent results. But how can we make it perform better? We need to optimize its hyperparameters. In our case, the decision tree model has a single hyperparameter `depth` which determines the depths of the decision tree.  \nLet's try out a number of different depths and see which one preforms best.\n\n::: {#66c2490a .cell editable='false' execution_count=14}\n``` {.python .cell-code}\ndepths = np.arange(1, 25, 2)\ndepths\n```\n\n::: {.cell-output .cell-output-display execution_count=14}\n```\narray([ 1,  3,  5,  7,  9, 11, 13, 15, 17, 19, 21, 23])\n```\n:::\n:::\n\n\n::: {#4ea95590 .cell tags='[]' execution_count=15}\n``` {.python .cell-code}\nresults_dict = {\n    \"depth\": [],\n    \"mean_train_score\": [],\n    \"mean_cv_score\": [],\n}\n\nfor depth in depths: # Create a model for each depth in our list, assess it, and add it to our results_df\n    model = DecisionTreeClassifier(max_depth=depth, random_state=123)\n    scores = cross_validate(model, X_train, y_train, cv=10, return_train_score=True)\n    results_dict[\"depth\"].append(depth)\n    results_dict[\"mean_cv_score\"].append(np.mean(scores[\"test_score\"]))\n    results_dict[\"mean_train_score\"].append(np.mean(scores[\"train_score\"]))\n\nresults_df = pd.DataFrame(results_dict)\nresults_df = results_df.set_index(\"depth\")\nresults_df\n```\n\n::: {.cell-output .cell-output-display execution_count=15}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>mean_train_score</th>\n      <th>mean_cv_score</th>\n    </tr>\n    <tr>\n      <th>depth</th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>0.651030</td>\n      <td>0.646032</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.733485</td>\n      <td>0.692524</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>0.794035</td>\n      <td>0.711713</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>0.858718</td>\n      <td>0.703060</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>0.912930</td>\n      <td>0.690610</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>0.955157</td>\n      <td>0.680048</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>0.980850</td>\n      <td>0.674457</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>0.993525</td>\n      <td>0.658979</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>0.998278</td>\n      <td>0.669538</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>0.999173</td>\n      <td>0.665812</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>0.999449</td>\n      <td>0.662706</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>0.999449</td>\n      <td>0.662706</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\nWe can see that in our case, depth 5 yields the best result: `0.711713`. However, we must also consider the **fundamental tradeoff**. We want our model to have the highest test scores, but if its training score is too high it may suggest that it is overfitting on our particular dataset and will generalize poorly to future unseen data. To take a closer look at this, let's plot our model's scores and see how they change as depth changes.\n\n::: {#40a8f8b0 .cell editable='true' slideshow='{\"slide_type\":\"\"}' tags='[]' execution_count=16}\n``` {.python .cell-code}\nresults_df[[\"mean_train_score\", \"mean_cv_score\"]].plot()\n```\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/cell-17-output-1.png){width=579 height=429}\n:::\n:::\n\n\n<!-- END QUESTION -->\n\n<br><br>\n\nWe can see that the `mean_cv_score` peaks at depth 5 then begins to decrease. Whereas the `mean_train_score` continuously increases. We can conclude that depth 5 is the ideal depth for our model in this use case. This is what we call \"The sweet spot\".\n\n## 7. Final model and test\n<hr>\n\nIn this section, we recreate our decision tree model using the optimized hyperparameter, then we test it and compare our results with out unoptimized and baseline models.\n\n::: {#2c437df0 .cell tags='[]' execution_count=17}\n``` {.python .cell-code}\nbest_model = DecisionTreeClassifier(max_depth=5, random_state=123)\nbest_model.fit(X_test, y_test)\ntest_score = best_model.score(X_test, y_test)\ntest_score\n```\n\n::: {.cell-output .cell-output-display execution_count=17}\n```\n0.8267326732673267\n```\n:::\n:::\n\n\nTo recap:\n- Baseline model score: ~0.51  \n- Unoptimized decision tree model score: ~0.67  \n- **Optimized decision tree model score**: ~0.83  \n\n",
    "supporting": [
      "index_files"
    ],
    "filters": [],
    "includes": {
      "include-in-header": [
        "<script src=\"https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js\" integrity=\"sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==\" crossorigin=\"anonymous\"></script>\n<script src=\"https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js\" integrity=\"sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==\" crossorigin=\"anonymous\" data-relocate-top=\"true\"></script>\n<script type=\"application/javascript\">define('jquery', [],function() {return window.jQuery;})</script>\n"
      ]
    }
  }
}